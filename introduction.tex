This past decade has witnessed the rapid advancement of immersive system technologies, including mixed-reality systems used in mission-critical aerospace and defense applications. However, design-time analysis of such high-assurance systems typically leaves out one key ingredient: the user. Even when aspects of user behavior are included in a system model, an assumption is often made that the user will respond rationally to stimuli and correctly perform specific procedures to achieve mission objectives. In mixed-reality systems, the interactions between the user, system, and environment are so entwined that they cannot be treated separately; they must be modeled and analyzed together to ensure the entire human-machine system is protected against a wide variety of failure modes and vulnerabilities. Doing so necessarily requires accurate models of human cognitive behavior as well as new formal analysis methods and tools that can provide the rigorous assurance needed before these systems can be safely and securely deployed.

The need for advanced analysis techniques for mixed-reality system designs is recognized by the US Department of Defense, as evidenced by the DARPA Intrinsic Cognitive Security (ICS) program, which kicked off in July 2024. ICS is studying the feasibility of applying formal methods to the cognitive modeling domain to verify that users of tactical mixed-reality systems will be protected from adversarial cognitive attacks. This new class of attack exploits the intimate connection between users and mixed-reality devices. 
%On ICS, Collins Aerospace is leading a team that includes RTX Technology Research Center, SIFT, Iowa State University, and Florida Institute of Technology to develop new formal analysis methods and tools for proving that mixed-reality systems, their users, and the missions in which they are deployed are protected from such attacks.
%
%Our team has a successful history of applying proof engineering to new problem domains. For example, we recently demonstrated the use of formal methods to prove security properties in high assurance embedded system designs and implementations~\cite{??}. On previous programs, we applied formal analysis to verify safety~\cite{??}, artificial intelligence~\cite{??}, and assurance~\cite{??} properties. 
On ICS, our team is developing the Modeling and Analysis Toolkit for Realizable Intrinsic Cognitive Security (MATRICS), which facilitates the development of provably secure mixed-reality systems. %through the following contributions:
%\begin{itemize}
%	\item \textbf{Cognitive Attack Pattern Knowledgebase}. Effective protection against cognitive attacks in mixed-reality systems requires an understanding of how an adversary may exploit a vulnerability. Currently, there is no public resource that captures and classifies this information. We are therefore building a public knowledgebase, similar to MITRE’s Common Attack Pattern Enumeration and Classification (CAPEC)~\cite{??}, but specific to the ICS domain. Online publication of the knowledgebase will provide a valuable tool to future extended-reality system developers, independent of the formal rigor they use to develop and analyze their systems.
%	\item \textbf{Formal Analysis of Combined Cognitive and Device Models}. We are developing proof engineering methods and tools that support an extensive combination of cognitive, environment, and device modeling formalisms that cover a broad swath of the cognitive attack space. Furthermore, we are developing models of mixed-reality human-machine designs, including aspects of cognitive and logical processes that can be formally analyzed in the context of ICS-relevant missions using these new proof methods and tools.  Because cognitive behavior is inherently stochastic, our approach necessarily involves reasoning probabilistically over models. 
%	\item \textbf{Mixed-Reality System Assurance Patterns}. Unlike traditional system cybersecurity, there is a lack of guidance for assuring that mixed-reality systems are protected from cognitive attack. Formal analysis results alone will not be sufficient. Ultimately, a comprehensive assurance case will need to be presented. We are therefore defining formative assurance patterns corresponding to the attack patterns in our knowledgebase. The assurance patterns will include the necessary arguments that a given mixed-reality system is protected from attack as well as specify the evidence required to substantiate the arguments’ claims. These assurance patterns will greatly facilitate evaluation and compliance activities for the broader extended-reality systems community.
%\end{itemize}

Because future immersive systems will touch everything from consumer electronics to high-assurance national security systems, rigorous analysis methods and evaluation criteria such as those being developed on DARPA ICS must be established (and matured) well in advance. In this paper, we provide an overview of MATRICS, as well as initial results demonstrating the feasibility of our approach.

